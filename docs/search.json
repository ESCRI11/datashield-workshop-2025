[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "DataSHIELD Workshop: Setting up the infrastructure",
    "section": "",
    "text": "Funding\n\n\nIntroduction\nThis site hosts materials for a hands‑on workshop on installing and operating DataSHIELD backends using Docker Compose. We will deploy Opal and Armadillo behind an Nginx reverse proxy, start locally with self‑signed TLS, and then show how to go live with Let’s Encrypt. Expect practical Linux/SSH usage from a terminal and a copy‑pasteable flow you can follow on your laptop.\n\n\nWorkshop Details\nThis workshop will be delivered at the DataSHIELD 2025 Conference in Lausanne (23-26 September 2025) on Tuesday, September 23rd from 13:30 to 16:30 at room POL-338 (TBC).\n\n\nGetting started\n\nReview your setup: Environment Setup\nSkim the essentials: Get up to speed\n\n\n\nWorkshop scope\n\nDeploy Opal and Armadillo with Docker Compose (no Kubernetes)\nNginx reverse proxy: local self‑signed → Let’s Encrypt\nBasic Linux/SSH workflows suitable for on‑prem and cloud\nOptional: lightweight monitoring with Telegraf + Grafana (time permitting)\n\n\n\nWho this is for\n\nBeginners to sysadmin tasks; we explain each step\nAttendees on macOS (Apple Silicon ok), Windows (Docker Desktop/WSL2), or Linux\nFollow‑along is encouraged but not mandatory\n\n\n\nPrerequisites (summary)\nSee details in Environment Setup. In short: - Docker Desktop (Mac/Windows) or Docker Engine + Compose v2 (Linux) - Terminal + SSH access; ability to open ports 80/443 locally - Optional domain name if you want to test live certificates\n\n\nSchedule\nTo be announced.\n\n\nCredits\nMaterials developed by Dick Postma (Molgenis) and Xavier Escribà Montagut (BigOmics Analytics SA).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "env_setup.html",
    "href": "env_setup.html",
    "title": "Environment Setup",
    "section": "",
    "text": "Prerequisites",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#prerequisites",
    "href": "env_setup.html#prerequisites",
    "title": "Environment Setup",
    "section": "",
    "text": "Operating System\n\nWindows Users: Ensure you have WSL2 installed. This allows you to run a Linux environment directly on Windows, which is necessary for Docker.\nMac and Linux Users: You are good to go with your native terminal.\nReference System: This workshop material has been tested on Ubuntu 24.04.3 LTS\n\n\n\nSoftware Requirements\n\nDocker Engine (&gt;= 28.3.3) with Docker Compose\n\nWindows/macOS: Docker Desktop bundles Docker Compose.\nLinux: Install Docker Engine and Docker Compose separately.\nRequired version: Docker Compose v2.39.2 or later\n\nGit (&gt;= 2.43.0)\n\nUsed for cloning workshop repositories and version control\nDownload from git-scm.com\nAlternative: GitHub Desktop for a graphical interface\nVerify installation: git --version\n\nTerminal or shell (PowerShell, Windows Terminal, macOS Terminal, Linux shell)\nText Editor/IDE: VS Code, Sublime, Vim, or similar.\nR (&gt;= 4.3.3) and RStudio Desktop (optional but recommended for client-side checks)\n\n\n\nHardware requirements\n\nAt least 4 CPU cores and 8 GB RAM recommended (4 GB minimum)\n10+ GB free disk space for images, containers, and volumes\n\n\n\nNetwork and permissions\n\nAdministrative rights to install software\nUnrestricted internet access to docker.io, ghcr.io and GitHub\nVPN/proxy configured for Docker if required by your organization\nVirtualization enabled in BIOS/UEFI (Intel VT-x/AMD-V or Apple virtualization)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#install-docker",
    "href": "env_setup.html#install-docker",
    "title": "Environment Setup",
    "section": "Install Docker",
    "text": "Install Docker\n\nWindows (WSL2)\n\nInstall and enable WSL2: Microsoft guide\nInstall Docker Desktop: Docker Desktop for Windows\nIn Docker Desktop settings, enable “Use the WSL 2 based engine” and integration with your WSL distro\n\n\n\nmacOS\n\nInstall Docker Desktop: Docker Desktop for Mac\n\n\n\nLinux\n\nInstall Docker Engine following the official docs: Install Docker Engine\nInstall Docker Compose (standalone): Install Docker Compose\n\n\nLinux post-install (non-root usage)\n# Add your user to the docker group and activate it\nsudo usermod -aG docker $USER\n# Restart your terminal to activate the changes",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#verify-your-setup",
    "href": "env_setup.html#verify-your-setup",
    "title": "Environment Setup",
    "section": "Verify your setup",
    "text": "Verify your setup\nRun the following commands. All should succeed without errors.\ndocker --version\ndocker-compose --version\ndocker run --rm hello-world\n\nExpected output (or newer versions):\nDocker version 28.3.3, build 980b856 Docker Compose version v2.39.2-desktop.1\n\nExpected output (or newer versions):\nDocker version 28.3.3, build 980b856\nDocker Compose version v2.39.2-desktop.1",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#additional-notes",
    "href": "env_setup.html#additional-notes",
    "title": "Environment Setup",
    "section": "Additional Notes",
    "text": "Additional Notes\n\nEnsure your Docker engine is allocated with sufficient memory (at least 4GB; 8GB recommended) to avoid performance issues.\nClose applications using typical service ports you plan to map (e.g., 8080, 8443) to avoid conflicts.\nOn corporate networks, confirm Docker can pull images from public registries.\nFamiliarize yourself with basic Docker commands and docker-compose operations, as we will be interacting with the console during the workshop.\nImportant: We use docker-compose (with hyphen) throughout this workshop, not docker compose (space-separated).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "env_setup.html#learn-docker-quick-references",
    "href": "env_setup.html#learn-docker-quick-references",
    "title": "Environment Setup",
    "section": "Learn Docker: quick references",
    "text": "Learn Docker: quick references\n\nDocker Getting Started: docs.docker.com/get-started\nDocker CLI reference: docs.docker.com/engine/reference/commandline/docker\nDocker Compose overview: docs.docker.com/compose\nVolumes and persistence: docs.docker.com/storage/volumes\nPlay with Docker (hands-on labs): labs.play-with-docker.com\n\nBy following these steps, your environment will be ready for the workshop. If you encounter any issues, feel free to reach out to the workshop organizers for assistance.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Environment Setup</span>"
    ]
  },
  {
    "objectID": "up_2_speed.html",
    "href": "up_2_speed.html",
    "title": "Get up to speed",
    "section": "",
    "text": "This workshop is a hands-on primer on installing and running secure, federated DataSHIELD backends with Docker Compose. We will deploy Opal and Armadillo behind an Nginx reverse proxy, start locally with self-signed TLS, and then show how to go live with Let’s Encrypt.\n\nWhat you’ll learn\n\nDeploy Opal and Armadillo using Docker Compose (no Kubernetes)\nRun Nginx as a reverse proxy: local self‑signed → Let’s Encrypt\nPractical Linux/SSH and terminal workflows (great for cloud)\nOptional: lightweight host monitoring with Telegraf + Grafana (time permitting)\n\n\n\nAudience and setup\n\nSkill level: beginner-friendly. We’ll explain each step as we go.\nFollow‑along encouraged on your laptop (Mac/Windows/Linux). If you prefer to watch, you’ll still get all commands and files.\n\n\n\nPrerequisites checklist (please skim before we start)\n\nLaptop: macOS (Apple Silicon is fine), Windows 10/11, or Linux\nContainers:\n\nmacOS/Windows: install Docker Desktop and ensure both docker and docker compose work\n\nDocker Desktop: docs\n\nLinux: install Docker Engine and Compose v2 plugin (we’ll use docker compose, not docker-compose)\n\nDocker Engine install: docs\nCompose v2 guidance: migrate\n\n\nTerminal + SSH: basic comfort with shell, ssh user@host\nPorts:\n\nLocal: allow Docker to bind 80/443 (stop other services using these ports)\nCloud (optional): if testing live TLS, ensure 22/80/443 are open\n\nDomain (optional, for live demo): have a test DNS name ready if you want to issue real certificates with Let’s Encrypt; otherwise we’ll stick to self‑signed locally\n\n\n\nTarget platforms we’ll mention\n\nOn‑prem demo first; cloud notes included\nCloud suggestion: Ubuntu 24.04 LTS on x86_64 for quick starts\n\n\n\nWhat we’ll deploy (at a glance)\n\nReverse proxy: Nginx\nDataSHIELD backends: Opal and Armadillo (latest images)\nR server (Rock) alongside Opal for DataSHIELD R packages\nStage 1 (local): self‑signed TLS\nStage 2 (live): DNS + Certbot for Let’s Encrypt on Ubuntu\n\n\n\n\n\n\n\nTip\n\n\n\nNo prior sysadmin experience required. We’ll keep commands copy‑pasteable and explain the “why” briefly as we go.\n\n\n\n\nPre‑reading (short and optional)\n\nDataSHIELD overview paper: International Journal of Epidemiology\nOpal (DataSHIELD server) overview: OBiBa Opal\nDataSHIELD packages documentation: cran.datashield.org\nDocker basics for this workshop:\n\nDocker Desktop (Mac/Windows): docs\nCompose v2 usage/migration: docs\n\nLet’s Encrypt on Ubuntu + Nginx (for Stage 2):\n\nCertbot + Nginx (Ubuntu): DigitalOcean guide\n\n\n\n\nWhat we will not cover\n\nKubernetes, advanced identity (OIDC/Keycloak), or firewall hardening beyond basics\nData layer specifics (databases/object storage) for Armadillo—kept out to stay focused on deployment flow\n\n\n\nOutcomes\nBy the end, you’ll have a working local deployment (Opal/Armadillo behind Nginx with TLS) and a clear path to promote it to a live DNS‑backed setup with Let’s Encrypt.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Get up to speed</span>"
    ]
  },
  {
    "objectID": "1-local-deploy.html",
    "href": "1-local-deploy.html",
    "title": "1. Deploying for local use",
    "section": "",
    "text": "Why start with local deployment?\n\nLocal keeps friction low: no DNS, firewalls, or cloud costs. You can validate the stack in minutes on any laptop.\nSafe sandbox: use HTTP and avoid exposing services to the internet while you explore features.\nDeveloper‑friendly: iterate on DataSHIELD code and packages against a predictable, reproducible environment.\nPortable: the same Compose foundation scales up later (add DNS, TLS, and hardening without changing core services).\nTeaching aid: a contained lab to learn Opal and Rock.\n\n\n\nArchitecture at a glance\n\n\n\n\n\ngraph LR\n  B[\"Browser&lt;br/&gt;http://localhost:8080\"] --&gt;|8080| O[\"Opal (8080)\"]\n  subgraph Profiles[\"docker network: opalnet\"]\n    O --&gt;|R/DataSHIELD| R[\"Rock (8085)\"]\n    O --&gt;|Auxiliary| MONGO[\"MongoDB (27017)\"]\n  end\n\n  %% Define a lighter background for the subgraph\n  classDef light fill:#f9f9f9,stroke:#aaa,stroke-width:1px;\n  class Profiles light;\n\n\n\n\n\n\n\n\nServices and roles\n\nOpal (OBiBa):\n\nMain DataSHIELD server and admin UI. Exposes HTTP on 8080.\nReads configuration via environment variables (e.g., OPAL_ADMINISTRATOR_PASSWORD, MONGO_*, ROCK_HOSTS) docs docs.\n\nRock (R server):\n\nExecutes R/DataSHIELD calls initiated by Opal, reachable as rock:8085 on the Docker network.\nShips with DataSHIELD packages; ideal for quick connectivity checks.\n\nMongoDB (auxiliary store):\n\nUsed by Opal for auxiliary features; we pin to mongo:6.0 per Opal guidance.\n\n\n\n\nGoal\nDeploy Opal locally on your laptop using Docker Compose. This lets you try DataSHIELD quickly without DNS or cloud setup and is perfect for package development and smoke tests. See the prerequisites in @env_setup.qmd and the scope in @up_2_speed.qmd.\n\n\nWhat we will deploy\n\nOpal server (obiba/opal:latest) with admin password set\nRock R server (datashield/rock-base:latest) for DataSHIELD execution\nMongoDB for auxiliary storage\n\nReferences: - Opal Docker image + env vars: Installation — Docker Image and Configuration - Templates adapted from: easy-opal compose template (docker-compose.yml.tpl); see also helper commands (src/commands)\n\n\nFiles layout\nUse this folder layout:\nopal-local/\n├── .env\n├── docker-compose.yml\n\n\n1) Create a .env file\nKeep secrets out of the compose file.\nOPAL_ADMINISTRATOR_PASSWORD=ChangeMe123!\n\nOPAL_ADMINISTRATOR_PASSWORD is required on first start of obiba/opal.\n\n\n\n\n\n\n\nNote\n\n\n\nProduction note: For production deployments, the most correct way to handle sensitive information is through Docker secrets, Kubernetes secrets, or your platform’s native secrets management system. We use a .env file here for workshop simplicity, which also helps reduce the risk of password leaks when sharing docker-compose files for reproducibility.\n\n\n\n\n2) docker-compose.yml\nDefines Opal, Rock, and MongoDB. Key env vars match Opal docs (MONGO_*, ROCK_HOSTS) opaldoc installation.\nservices:\n  opal:\n    image: obiba/opal:latest\n    depends_on:\n      - rock\n      - mongo\n    ports:\n      - \"8080:8080\"\n      - \"8443:8443\"\n    environment:\n      - OPAL_ADMINISTRATOR_PASSWORD=${OPAL_ADMINISTRATOR_PASSWORD}\n      - MONGO_HOST=mongo\n      - MONGO_PORT=27017\n      - ROCK_HOSTS=rock:8085\n    volumes:\n      - opal_srv:/srv\n  mongo:\n    image: mongo:6.0\n    volumes:\n      - mongo_data:/data/db\n\n  rock:\n    image: datashield/rock-base:latest\n    environment:\n    - ROCK_ID=new-stack-rock\n\nvolumes:\n  opal_srv:\n  mongo_data:\n\nnetworks:\n  opalnet:\nHighlights: - Opal sees Rock at rock:8085 and MongoDB via service names on the internal network. - Opal is directly accessible on port 8080 for simplicity. - All services run on the opalnet Docker network.\n\n\n3) Bring it up\nFrom the directory containing docker-compose.yml and .env:\ndocker compose up -d\n# First start may take a minute while images are pulled.\n\n# Check health\ndocker compose ps\ndocker compose logs -f opal | cat\n\nOpen http://localhost:8080 in your browser.\nLogin with user administrator and the password you set in .env.\n\nIf you see the Opal UI and can navigate the Admin area, your stack is running.\n\n\n4) Minimal DataSHIELD test (R)\nVerify connectivity via DSOpal/DSI.\nlibrary(DSI)\nlibrary(DSOpal)\nlibrary(httr)\nset_config(config(ssl_verifyhost = 0L, ssl_verifypeer = 0L))\nlibrary(dsBaseClient)\n\n\nb &lt;- DSI::newDSLoginBuilder()\nb$append(\n    server   = \"local\",\n    url      = \"http://localhost:8080\",\n    user     = \"administrator\",\n    password = \"ChangeMe123!\",\n    profile = \"default\"\n)\n\nlogins &lt;- b$build()\nconns &lt;- DSI::datashield.login(logins)\nds.ls()\nNotes: - The Opal + Rock images are DataSHIELD‑ready by design. If a package appears missing, ensure Rock pulled the latest image or install required packages in Rock. - For real deployments, use HTTPS with proper certificates and omit the SSL verification overrides.\n\n\nTroubleshooting\n\nOpal not reachable: check if port 8080 is available locally.\nLogin fails: ensure OPAL_ADMINISTRATOR_PASSWORD was set at first start; to reset, stop containers, remove opal_srv volume, and start again.\nMongo version: Opal expects MongoDB ≤ 6.0; using mongo:6.0 matches docs.\nRock connection issues: check that Rock container is running and healthy.\n\n\n\nNext steps\nWhen ready to go live, add Nginx reverse proxy with TLS, DNS configuration, and hardening as we’ll cover in the later section. For now, you have a working local Opal + DataSHIELD lab.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>1. Deploying for local use</span>"
    ]
  },
  {
    "objectID": "3-add-profiles.html",
    "href": "3-add-profiles.html",
    "title": "3. Managing profiles",
    "section": "",
    "text": "Goal\nLearn how to add new DataSHIELD profiles to your local Opal deployment from section 1. This builds directly on the simple local setup, showing you how to extend it with multiple profiles without losing data or adding production complexity.\n\n\nWhat are profiles?\nProfiles in Opal/DataSHIELD are named configurations that can include: - Specific sets of DataSHIELD packages - Different R package versions - Custom package repositories - Environment-specific configurations\nThink of profiles as isolated R environments within your Opal deployment, similar to Python virtual environments, but for DataSHIELD research contexts.\n\n\nPrerequisites\n\nWorking local Opal deployment from section 1\nBasic understanding of Docker Compose\nYour local deployment should be running and accessible at http://localhost:8080\n\n\n\nCommon use cases for profiles\n\nResearch-specific environments: Different studies requiring different package versions\nDevelopment vs. stable: Testing new packages before using them in research\nPackage version management: Maintaining stable versions while testing updates\nLearning: Experimenting with different DataSHIELD packages safely\n\n\n\nArchitecture with profiles (local)\n\n\n\n\n\ngraph TB\n  B[\"Browser&lt;br/&gt;http://localhost:8080\"] --&gt; O[\"Opal Server (8080)\"]\n  O --&gt; R1[\"Rock Profile: default&lt;br/&gt;dsBase, dsStats\"]\n  O --&gt; R2[\"Rock Profile: genomics&lt;br/&gt;dsOmics, dsExposure\"] \n  O --&gt; R3[\"Rock Profile: survival&lt;br/&gt;dsSurvival\"]\n  subgraph Profiles[\"docker network: opalnet\"]\n    R1 --&gt; P1[\"rock-default:8085\"]\n    R2 --&gt; P2[\"rock-genomics:8085\"] \n    R3 --&gt; P3[\"rock-survival:8085\"]\n  end\n\n  %% Define a lighter background for the subgraph\n  classDef light fill:#f9f9f9,stroke:#aaa,stroke-width:1px;\n  class Profiles light;\n\n\n\n\n\n\n\n\nStarting point: Your local deployment\nFrom section 1, you should have this structure:\nopal-local/\n├── .env\n└── docker-compose.yml\nWe’ll extend this by adding new Rock services for each profile.\n\n\nStep 1: Update your .env file\nYour .env file from section 1 only needs the password. No changes required:\nOPAL_ADMINISTRATOR_PASSWORD=ChangeMe123!\n\n\nStep 2: Extend docker-compose.yml with profiles\nReplace your docker-compose.yml from section 1 with this extended version that adds genomics and survival profiles:\nservices:\n  opal:\n    image: obiba/opal:latest\n    depends_on:\n      - rock-default\n      - rock-genomics\n      - rock-survival\n      - mongo\n    ports:\n      - \"8080:8080\"\n      - \"8443:8443\"\n    environment:\n      - OPAL_ADMINISTRATOR_PASSWORD=${OPAL_ADMINISTRATOR_PASSWORD}\n      - MONGO_HOST=mongo\n      - MONGO_PORT=27017\n      # Multiple Rock hosts - comma separated\n      - ROCK_HOSTS=rock-default:8085,rock-genomics:8085,rock-survival:8085\n    volumes:\n      - opal_srv:/srv\n    networks:\n      - opalnet\n\n  # Default profile (same as section 1, just renamed)\n  rock-default:\n    image: datashield/rock-base:latest\n    environment:\n      - ROCK_ID=default\n    networks:\n      - opalnet\n\n  # New genomics profile\n  rock-genomics:\n    image: datashield/rock-base:latest\n    environment:\n      - ROCK_ID=genomics\n    networks:\n      - opalnet\n\n  # New survival analysis profile  \n  rock-survival:\n    image: datashield/rock-base:latest\n    environment:\n      - ROCK_ID=survival\n    networks:\n      - opalnet\n\n  # MongoDB (unchanged from section 1)\n  mongo:\n    image: mongo:6.0\n    volumes:\n      - mongo_data:/data/db\n    networks:\n      - opalnet\n\nvolumes:\n  opal_srv:\n  mongo_data:\n\nnetworks:\n  opalnet:\n\n\nStep 3: Apply changes with maintenance window\n\n\n\n\n\n\nWarning\n\n\n\nService Interruption: Adding or removing profiles requires stopping the Opal service, which will temporarily interrupt access for all users. Plan a maintenance window and notify users in advance.\n\n\nThe key to adding profiles without losing your existing data is to preserve the named volumes:\n# 1. Stop all services (but preserve data volumes)\ndocker-compose stop\n\n# 2. Update your docker-compose.yml file (copy the extended version above)\n\n# 3. Start the new configuration\ndocker-compose up -d\n\n# 4. Verify all services are healthy\ndocker-compose ps\nImportant: Never run docker-compose down as this removes the named volumes containing your data. Always use docker-compose stop for graceful shutdowns.\n\n\nStep 4: Verify your profiles are running\nCheck that all Rock containers are running:\n# Check container status\ndocker-compose ps\n\n# Check logs for each profile\ndocker-compose logs rock-default\ndocker-compose logs rock-genomics  \ndocker-compose logs rock-survival\nYou should see all three Rock containers running and healthy.\n\n\nAdding a single profile (step-by-step)\nIf you want to add just one profile at a time, here’s the simplified process:\n\n1) Update docker-compose.yml\nAdd the new Rock service to the services: section:\n  rock-newprofile:\n    image: datashield/rock-base:latest\n    environment:\n      - ROCK_ID=newprofile\n    networks:\n      - opalnet\nAnd update the ROCK_HOSTS environment variable in the opal service:\n- ROCK_HOSTS=rock-default:8085,rock-genomics:8085,rock-survival:8085,rock-newprofile:8085\n\n\n2) Apply the changes (with maintenance window)\n# Stop all services\ndocker-compose stop\n\n# Start with new configuration\ndocker-compose up -d\n\n\n\nRemoving a profile\nTo remove a profile safely:\n\n1) Update docker-compose.yml\n\nDelete the entire rock-genomics: service block\nRemove rock-genomics:8085 from the ROCK_HOSTS environment variable\n\n\n\n2) Apply the changes (with maintenance window)\n# Stop all services\ndocker-compose stop\n\n# Start with updated configuration\ndocker-compose up -d\n\n# Clean up the removed container (optional)\ndocker-compose rm rock-genomics\n\n\n\n\n\n\nNote\n\n\n\nMaintenance Planning: Profile changes require a brief service interruption. For production deployments, schedule these changes during low-usage periods and communicate the maintenance window to users.\n\n\n\n\n\nConfiguring profiles in Opal UI\nAfter your Rock containers are running, configure them in the Opal web interface:\n\nAccess Opal: Navigate to http://localhost:8080 and login as administrator\nGo to DataSHIELD Configuration:\n\nClick on “Administration” in the top menu\nSelect “DataSHIELD” from the left sidebar\n\nAdd Rock Servers:\n\nClick “Add DataSHIELD Configuration”\nName: genomics\nURL: http://rock-genomics:8085\nClick “Save”\nRepeat for other profiles\n\nTest connectivity: Each profile should show as “Available” in the DataSHIELD configurations list\n\n\n\nTesting your profiles from R\nVerify each profile works correctly:\nlibrary(DSI)\nlibrary(DSOpal)\nlibrary(httr)\n# Disable SSL verification for local testing\nset_config(config(ssl_verifyhost = 0L, ssl_verifypeer = 0L))\n\n# Test genomics profile\nbuilder &lt;- DSI::newDSLoginBuilder()\nbuilder$append(\n  server = \"genomics\",\n  url = \"http://localhost:8080\",\n  user = \"administrator\", \n  password = \"ChangeMe123!\",\n  driver = \"Opal\",\n  profile = \"genomics\"  # Specify the profile\n)\n\nlogins &lt;- builder$build()\nconns &lt;- DSI::datashield.login(logins)\n\n# Check available packages\nDSI::datashield.pkg_status(conns)\n\nDSI::datashield.logout(conns)\n\n\nCommon profile patterns\n\nResearch-focused profiles\n# Genomics research\nrock-genomics:\n  image: datashield/rock-base:latest\n  environment:\n    - ROCK_ID=genomics\n\n# Epidemiology research  \nrock-epi:\n  image: datashield/rock-base:latest\n  environment:\n    - ROCK_ID=epidemiology\n\n# Survival analysis\nrock-survival:\n  image: datashield/rock-base:latest\n  environment:\n    - ROCK_ID=survival\n\n\nDevelopment vs stable\n# Stable production packages\nrock-stable:\n  image: datashield/rock-base:latest\n  environment:\n    - ROCK_ID=stable\n\n# Testing new packages\nrock-dev:\n  image: datashield/rock-base:latest\n  environment:\n    - ROCK_ID=development\n\n\n\nTroubleshooting profiles\n\nProfile not appearing in Opal UI\n# Check Rock container is running\ndocker-compose ps\n\n# Check Rock container logs for errors\ndocker-compose logs rock-genomics\n\n# Test network connectivity from Opal to Rock\ndocker-compose exec opal curl -f http://rock-genomics:8085/\n\n\nConnection timeouts\n\nVerify the ROCK_HOSTS environment variable includes all profiles\nCheck that service names match between docker-compose.yml and ROCK_HOSTS\nEnsure all containers are on the same network (opalnet)\n\n\n\nMemory issues\n# Monitor container resource usage\ndocker stats\n\n# If running low on memory, consider:\n# 1. Reducing the number of active profiles\n# 2. Stopping unused profiles temporarily\ndocker-compose stop rock-genomics\n\n\n\nBest practices for local development\n\nStart simple: Begin with 2-3 profiles, add more as needed\nConsistent naming: Use descriptive profile names\n\ndefault for standard DataSHIELD packages\ngenomics for omics analysis\nsurvival for survival analysis\ndev for testing new packages\n\nDocument your profiles: Keep a simple list\n# My DataSHIELD Profiles\n- default: dsBase, dsStats\n- genomics: dsOmics, dsExposure  \n- survival: dsSurvival\nTest regularly: After adding profiles, test connectivity from R\nClean up unused profiles: Remove profiles you’re not using to save resources\n\n\n\nNext steps\nWith profiles working locally, you can: - Install different packages in each profile using the Opal UI - Create project-specific profile assignments - Test new DataSHIELD packages safely in development profiles - Scale up to production deployment (sections 2 and beyond) when ready\nThis local multi-profile setup gives you a powerful development environment for DataSHIELD research while keeping complexity manageable.\n\n\nReferences\n\nOpal DataSHIELD configuration: DataSHIELD Administration\nRock server documentation: Rock Server\nDocker Compose services: Docker Compose Services",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>3. Managing profiles</span>"
    ]
  },
  {
    "objectID": "4-creating-a-rock-server.html",
    "href": "4-creating-a-rock-server.html",
    "title": "4. Creating custom Rock server images",
    "section": "",
    "text": "Goal\nLearn how to build custom Rock server Docker images with specific DataSHIELD packages and versions. This allows you to create reproducible, version-controlled profiles that can be shared across deployments.\n\n\nWhy build custom Rock images?\nWhile the previous section showed how to add profiles using the standard obiba/rock:latest image, building custom images provides several advantages:\n\nVersion control: Pin specific package versions for reproducibility\nConsistency: Ensure all environments use identical package versions\n\n\n\nPrerequisites\n\nDocker installed and running\nBasic understanding of Dockerfiles\nUnderstanding of R package dependencies\n\n\n\nUnderstanding the base image\nDataSHIELD provides base images that you can extend:\n\ndatashield/rock-base:6.3-R4.3: Minimal Rock server with R 4.3\nobiba/rock:latest: Standard Rock with common DataSHIELD packages pre-installed\n\n\n\n\n\n\n\nNote\n\n\n\nDataSHIELD base images follow the pattern {dsBase-version}-R{R-version}. In the example above, 6.3-R4.3 means dsBase version 6.3 with R version 4.3.\n\n\nFor custom builds, start with rock-base for maximum control over package versions.\n\n\nExample: Survival analysis profile\nHere’s a complete example for creating a survival analysis Rock image:\n\n1) Create the Dockerfile\nDockerfile.survival:\n#\n# Rock R Server Dockerfile with DataSHIELD Survival profile\n#\n# Based on: https://github.com/datashield/docker-rock\n#\n\nFROM datashield/rock-base:6.3-R4.3\n\n# Define package versions for reproducibility\nENV DSURVIVAL_VERSION v2.3.0-dev\n\n# Rock library path\nENV ROCK_LIB /var/lib/rock/R/library\n\n# Install DataSHIELD packages with specific versions\n\n# dsSurvival (survival analysis functions)\nRUN Rscript -e \"remotes::install_github('datashield/dsSurvival', ref = '$DSURVIVAL_VERSION', dependencies = TRUE, upgrade = FALSE, lib = '$ROCK_LIB')\"\n\n# Fix ownership (Rock runs as non-root user)\nRUN chown -R rock $ROCK_LIB\n\n\n2) Build the image\n# Build the image with a descriptive tag\ndocker build -f Dockerfile.survival -t rock-survival:v2.3.0 .\n\n# Alternative: Build with multiple tags\ndocker build -f Dockerfile.survival \\\n  -t rock-survival:v2.3.0 \\\n  -t rock-survival:latest \\\n  .\n\n\n3) Test the image locally\n# Run the custom image\ndocker run -d --name test-survival-rock \\\n  -p 8085:8085 \\\n  rock-survival:v2.3.0\n\n# Check that packages are installed\ndocker exec test-survival-rock Rscript -e \"library(dsSurvival); packageVersion('dsSurvival')\"\n\n# Clean up\ndocker stop test-survival-rock\ndocker rm test-survival-rock\n\n\n\nUsing custom images in docker-compose\nUpdate your docker-compose.yml to use the custom images:\nservices:\n  opal:\n    # ... existing opal configuration\n    environment:\n      - ROCK_HOSTS=rock-default:8085,rock-survival:8085\n    # ... rest of configuration\n\n  rock-default:\n    image: obiba/rock:latest  # Standard image\n    container_name: rock-default\n    networks:\n      - opalnet\n    environment:\n      - ROCK_ID=default\n\n  rock-survival:\n    image: rock-survival:v2.3.0  # Your custom image\n    container_name: rock-survival\n    networks:\n      - opalnet\n    environment:\n      - ROCK_ID=survival\n\n\nImage management and distribution\n\nTagging strategy\nUse semantic versioning for your custom images:\n# Development versions\ndocker build -t rock-survival:v2.3.0-dev .\n\n# Release versions\ndocker build -t rock-survival:v2.3.0 .\ndocker build -t rock-survival:latest .\n\n# Environment-specific tags\ndocker build -t rock-survival:production .\ndocker build -t rock-survival:staging .\n\n\nPushing to a registry\nA Docker registry is a centralized repository for storing and distributing Docker images. It allows you to share images across different environments and with other developers. Docker Hub is the most popular free registry service provided by Docker, offering public repositories for open-source projects and private repositories for proprietary code.\n# Tag for your registry\ndocker tag rock-survival:v2.3.0 your-registry.com/rock-survival:v2.3.0\n\n# Push to registry\ndocker push your-registry.com/rock-survival:v2.3.0\nIn the case of using Docker Hub, you can use the following command to push your image to the registry:\ndocker tag rock-survival:v2.3.0 your-dockerhub-username/rock-survival:v2.3.0\ndocker push your-dockerhub-username/rock-survival:v2.3.0\n\n\n\nTroubleshooting image builds\n\nCommon build issues\nPackage installation failures:\n# Add error handling\nRUN Rscript -e \"\n    tryCatch({\n        remotes::install_github('datashield/dsBase', lib = '$ROCK_LIB')\n    }, error = function(e) {\n        cat('Error installing dsBase:', e$message, '\\n')\n        quit(status = 1)\n    })\n\"\nPermission issues:\n# Ensure proper ownership at each step\nRUN Rscript -e \"remotes::install_github('datashield/dsBase', lib = '$ROCK_LIB')\" \\\n    && chown -R rock $ROCK_LIB\nBuild context too large:\n# Check build context size\ndu -sh .\n\n# Use .dockerignore to exclude large files\necho \"*.log\" &gt;&gt; .dockerignore\necho \"data/\" &gt;&gt; .dockerignore\n\n\nDebugging build failures\n# Build with no cache to see all steps\ndocker build --no-cache -f Dockerfile.survival .\n\n# Interactive debugging\ndocker run -it --rm datashield/rock-base:6.3-R4.3 /bin/bash\n\n# Check intermediate layers\ndocker build -f Dockerfile.survival -t debug-build .\ndocker run -it debug-build /bin/bash\n\n\n\nBest practices\n\nVersion everything: Pin package versions and base image tags\nUse multi-stage builds: Keep final images small\nLayer efficiently: Order Dockerfile commands by change frequency\nTest thoroughly: Automate testing of built images\nDocument well: Include package versions and build instructions\n\n\n\nReferences\n\nDataSHIELD Docker images: docker-rock",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>4. Creating custom Rock server images</span>"
    ]
  }
]